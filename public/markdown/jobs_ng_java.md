# ASP JOB APPLICATION TRACKER ğŸ“ˆ

## ğŸ“Œ About This Project

This app was inspired by my own job search journey. I started by tracking applications in a notepad, but quickly realized I needed something more structured.

The first version was built with **Next.js** on the frontend and **Python** on the backend. Later, I rebuilt the backend in **Java**, focusing on scalability and cleaner API design while keeping the **Next.js** client.

Now, Iâ€™m rebuilding the client in **Angular**, and with the backend already developed and tested, I can focus entirely on the interface.

---

## ğŸ§± Tech Stack

The name **ASP** comes from the core stack that powers the project:

- **A** => **Angular** for building the client interface
- **S** => **Spring Boot** for the backend logic and API layer
- **P** => **PostgreSQL** for handling data persistence and storage

Together they form a clean, modern **full-stack architecture** ğŸš€

---

### ğŸ–¥ï¸ **Client**

- **Angular 20** â€” Zoneless frontend framework with SSR support and Signals for fine-grained reactivity
- **TypeScript** â€” A typed superset of JavaScript for safer, maintainable code
- **RxJS** â€” Reactive programming library for handling asynchronous data streams
- **NgRx (Store + Effects)** â€” Predictable global state management and side-effect handling built on **RxJS**
- **Angular Forms + Zod** â€” Reactive form handling with schema-based, type-safe validation
- **Angular HTTPClient** â€” Built-in HTTP module with interceptors for secure API integration
- **Tailwind CSS** + **Sass** â€” Utility-first CSS with extended support for custom and complex designs
- **Motionone** â€” Modern animation library for the DOM with concise syntax similar to **Framer Motion** (React)
- **svg_ng_cli** â€” Custom **Python** CLI tool that parses SVG files into Angular components with dynamic color and size bindings

---

### ğŸ’¾ **Server**

- **Java 21** â€” Primary backend language
- **Spring Boot (WebFlux)** â€” Reactive, non-blocking backend framework powered by an **event-loop** execution model
- **Project Reactor** â€” Core reactive foundation powering **WebFlux**, **R2DBC**, and **Redis** for fully non-blocking data flows
- **PostgreSQL + R2DBC** â€” Asynchronous database access with reactive drivers
- **Liquibase** â€” Database migrations, written in raw SQL for full control
- **Redis (Lettuce)** â€” Async/reactive Redis client for caching and real-time data
- **Cloudinary (Reactive WebClient)** â€” Manually integrated using Springâ€™s WebClient, enabling fully non-blocking image and video uploads
- **JavaMailSender (MimeMessage)**â€” For sending HTML email content, including transactional emails built with custom, hand-crafted templates for full control over design and layout
- **java_pkg_cli** â€” Custom **Python** CLI utility to automatically add dependencies to both the **TOML catalog** and **Gradle build file**, eliminating repetitive hardcoding and improving consistency in dependency management

---

### ğŸ§ª **Testing & Quality**

- **Playwright** â€” End-to-end testing for UI flows
- **Vitest** â€” Unit testing for the client
- **JUnit Jupiter** â€” Unit and integration testing for the backend
- **Postman** â€” API testing
- **Checkstyle, SpotBugs, PMD** â€” Static analysis and code quality enforcement for Java

---

### ğŸ› ï¸ **DevOps & Deployment**

- **Turborepo** â€” Monorepo project structure for managing client and server together, with coordinated scripts and parallel builds
- **Docker** â€” Ensures consistent environments for development and production across both client and server
- **Docker Hub** â€” Publishing and managing images
- **Kind** â€” Run local Kubernetes clusters for development
- **GitHub Actions** â€” Automated pipelines for testing, building, and deploying both apps
- **Fly.io** â€” Hosting platform (client and server deployed as separate services)
- **Supabase** â€” PostgreSQL hosting
- **Upstash** â€” Hosting platform for Redis
- **Brevo (SMTP)** â€” Outbound transactional email delivery
- **Zoho Mail** â€” Inbound email hosting for custom domain addresses
- **Namecheap** â€” Domain provider, configured with DNS records (SPF, DKIM, DMARC) to support both Brevo + Zoho
- **Zsh** â€” Custom shell scripts for scaffolding and developer productivity
- **sync_env_cli** â€” Custom **Python** CLI tool that synchronizes environment variables across the client and server directories, updates **Kubernetes** secrets, and patches environment variables in the Git-based **CI/CD pipeline** for deployment.

---

## ğŸ“¦ Setup

After cloning the repository, start by installing the dependencies:

```bash
yarn install && yarn install_pkg
```

This will initialize the project and install all required packages for both client and server.

---

### ğŸ”’ Environment Variables

All required environment variables are listed in:

[`apps/server/app/src/main/resources/application.yml`](apps/server/app/src/main/resources/application.yml)

This file not only configures the server but also declares the environment variables required by the application.

- **Main runtime** variables are grouped under the top-level key **app**.

- **Mail service** settings are located under **spring.mail**.

- **Database connection** settings are under **spring.r2dbc**.

- **ğŸ’¡Note**:
  The same variables must also be present in a **kind-secrets.yml** file (not committed to git). This file is required if you want to run the app in a local **Kubernetes cluster** via **Kind**.
  A template for this file looks like:

  ```bash
  apiVersion: v1
  kind: Secret
  metadata:
  name: asp-job-application-tracker
  type: Opaque
  stringData:
  APP_NAME: "asp-job-application-tracker"
  ...rest key value pairs variables
  ```

---

### ğŸ“œ Scripts

To streamline development, I created a set of helper scripts located in the [**scripts**](scripts) folder.  
They are written in **Zsh**, so you can either copy them into your **.zshrc** file or place them wherever you normally keep custom scripts.

---

### ğŸ› ï¸ Build & Run

To start a development session, run:

```bash
yarn dev
```

This command uses **Turborepo** to run both the **Java server** and the **Angular client** in parallel:

- â˜• **Java** runs at [http://localhost:3000](http://localhost:3000)
- ğŸŸ¦ **Angular** runs at [http://localhost:3001](http://localhost:3001)

---

To build the app, run:

```bash
yarn build
```

This triggers **Turborepo** to build both the client and server in parallel:

- â˜• **Java** Compiles to bytecode and produces a `.jar` file at [apps/server/app/build/libs/server-1.0.0.jar](apps/server/app/build/libs/server-1.0.0.jar)
- ğŸŸ¦ **Angular** Runs the Angular build pipeline and generates output according to the rendering configuration defined in [apps/client/src/app/app.routes.server.ts](apps/client/src/app/app.routes.server.ts)

---

Once the build is complete, you can start servers with:

```bash
yarn start
```

This again uses **Turborepo** to launch both the **Java server** and the **Next.js client** in parallel:

- â˜• **Python** runs at [http://localhost:3000](http://localhost:3000)
- ğŸŸ¦ **Angular** is served at [http://localhost:3001](http://localhost:3001)

---

### ğŸ‹ Docker

#### ğŸ› ï¸ Build

To build the **client** Docker image, run:

```bash
dbc
```

---

To build the **server** Docker image, run:

```bash
dbs
```

---

#### ğŸ³ Start

To start a container:

- **Server**

```bash
dsi 0
```

- **Client**

```bash
dsi 1
```

---

#### ğŸ”— Result

- ğŸŸ¦ **Angular** is packaged into a Docker image and served from a container at [http://localhost:3001](http://localhost:3001)
- â˜• **Java** compile to bytecode and the generated **.jar** file is run inside a container at [http://localhost:3000/api/v1](http://localhost:3000/api/v1)

---

### ğŸ”€ Nginx Reverse Proxy

To mirror the production setup, I use an **Nginx reverse proxy** that listens on port **443 (HTTPS)** and routes requests to the correct service:

- In **development**:

  - â˜• Server => port **3000**
  - ğŸŸ¦ Client => port **3001**

- In **Kubernetes**:
  - â˜• Server => port **30080**
  - ğŸŸ¦ Client => port **30081**

This setup provides a **single HTTPS entrypoint** while internally forwarding traffic to the right service.  
It also avoids the need for a separate `kind` mode (like `ENV_M0DE=kind`) â€” Nginx handles all routing automatically.

Configuration files can be found at [nginx](nginx)

---

#### ğŸ”„ Switching Between Environments

Instead of hardcoding routes, the last line **include /etc/nginx/env/active.conf** in the [nginx/nginx.conf](nginx/nginx.conf) file acts as an entrypoint for environment-specific configs.

The script [`ngx`](scripts/nginx/ngx) in **scripts/nginx** manages a **symlink** (active.conf) that points to the right environment file:

- **Development** => /etc/nginx/env/dev.conf
- **Kubernetes** => /etc/nginx/env/kind.conf

---

##### ğŸ› ï¸ Development config

Running

```bash
ngx
```

Activates dev.conf

---

##### ğŸ’¾ Kind config

Running

```bash
ngx k
```

Activates kind.conf

---

### ğŸš¢ Kubernetes

To start a local **Kubernetes Cluster** run

```bash
kcc
```

The script present in [scripts/kind.zsh](scripts/kind.zsh) will

- **Create the cluster** using **Kind** passing the config file at repo root
- **Apply secrets** defined in **kind-secrets.yml**
- **Deploy the applications** using the manifests located in:

  - [`apps/client/kind-deploy.yml`](apps/client/kind-deploy.yml)
  - [`apps/client/kind-service.yml`](apps/client/kind-service.yml)
  - [`apps/server/kind-deploy.yml`](apps/server/kind-deploy.yml)
  - [`apps/server/kind-service.yml`](apps/server/kind-service.yml)

#### ğŸ”— Access

- **Client** => available at **[http://localhost:30081](http://localhost:30081)**
- **Server** => available at **[http://localhost:30080](http://localhost:30080)**

If youâ€™ve set up the **Nginx reverse proxy** (see section above), it will automatically route these internal ports behind a single HTTPS entrypoint (port 443).

---

### âš—ï¸ Testing & Type Checking & Code Quality

#### âœ’ï¸ Type Checking & Code Quality

- **Client**: Formatting with **ESLint** â€¢ Type checking with **TypeScript**
- **Server**:
  - Code style enforcement with **Checkstyle**
  - Code quality checks with **PMD**
  - Bug detection with **SpotBugs**

Run:

```bash
yarn check
```

---

#### ğŸ§ª Tests

If your development environment uses **HTTPS** (via Nginx or another proxy), youâ€™ll need an additional set of environment variables for testing.

---

Running every test with `ng serve` directly can be slow and flaky due to rebuild times.  
To improve stability and speed, the recommended workflow is:

1. **Build** the app

   ```bash
   yarn build:test
   ```

2. **Start** both client & server

   ```bash
   yarn start
   ```

3. **Run tests** in parallel for both client & server, using the maximum number of workers available on your machine:

   ```bash
   yarn tests
   ```

---

##### ğŸŸ§ Postman testing

A ready-to-use **Postman setup** is available at the root of the repo in the **postman directory**:

- [TEST_API.postman_collection.json](/postman/TEST_API.postman_collection.json) â€” Contains all API request
- [ENV_VAR.postman_environment.json](postman/ENV_VAR.postman_environment.json) â€” Contains the required environment variables
- [scripts](/postman/scripts/) â€” Contains reusable scripts used during testing to improve **efficiency**

---

## ğŸ˜ PostgreSQL Tables Shape

```mermaid
erDiagram
  users ||--o{ tokens : has
  users ||--o{ backup_codes : has
  users ||--o{ applications : has
  tokens }o--|| token_t : uses
  tokens }o--|| alg_t : uses
  applications }o--||application_status_t : uses
  root_table ||--|| users : extends
  root_table ||--|| tokens : extends
  root_table ||--|| backup_codes : extends
  root_table ||--|| applications : extends

  root_table {
    uuid id
    bigint created_at
    bigint updated_at
    bigint deleted_at
  }

  users {
    string first_name
    string last_name
    string email
    string tmp_email
    string password
    string totp_secret
    boolean is_verified
  }

  backup_codes {
    uuid user_id
    string code
  }

  tokens {
    uuid user_id
    token_t token_type
    alg_t alg_type
    string hashed
    bigint exp
  }

  applications {
    uuid user_id
    string company_name
    string position_name
    applications_status_t status
    string notes
    bigint applied_at
  }

  token_t {
    enum REFRESH
    enum CONF_EMAIL
    enum RECOVER_PWD
    enum RECOVER_PWD_2FA
    enum CHANGE_EMAIL
    enum CHANGE_EMAIL_2FA
    enum CHANGE_PWD
    enum MANAGE_ACC
    enum LOGIN_2FA
    enum MANAGE_ACC_2FA
  }

  alg_t {
    enum AES_CBC_HMAC_SHA256
    enum RSA_OAEP_256_A256GCM
    enum HMAC_SHA256
  }

  application_status_t {
  enum APPLIED
  enum UNDER_REVIEW
  enum INTERVIEW
  enum OFFER
  enum REJECTED
  enum WITHDRAWN
  }
```

---

## ğŸ› ï¸ CI/CD

The pipeline is defined in [`GitHub Workflows`](.github/workflows/check_deploy.yml) and runs automatically on every push to the **main** branch.

### ğŸš§ Workflow Stages

1. **Lint & Type Checking**

   - Runs `yarn check` to validate both client and server code.

2. **Tests**

   - Run `yarn test` for both client and server to ensure code quality and prevent regression.

3. **Deployment to Fly.io**

   - Client and server are hosted separately, each with its own Dockerfile.
   - **Server** is built and deployed first, ensuring itâ€™s available for any API requests during client build.
   - **Client** is then built and deployed. Static pages that rely on API data can safely query the newly deployed server.

---

This way it:

- Ensures **zero broken builds** reach production.
- Keeps **frontend and backend deployments independent** but coordinated.
- Automates the whole dev => deploy cycle with minimal manual intervention.

---

## âš™ï¸ Python CLI Tools

### ğŸ“‚ Working Directory

Each CLI tool can be executed directly from its relative project directory:

- **Java package manager CLI:** [`apps/server/java_pkg_cli`](apps/server/java_pkg_cli)
- **SVG parser CLI:** [`apps/client/svg_ng_cli`](apps/client/svg_ng_cli)
- **Env sync CLI:** [`sync_env_cli`](sync_env_cli)

Alternatively, you can use helper shell scripts to run the tools from anywhere without changing directories:

- ğŸ“¦ **ja** => located at [`scripts/java.zsh`](scripts/java.zsh)
- ğŸ¨ **ngcv** => located at [`scripts/svg.zsh`](scripts/svg.zsh)
- ğŸ” **ue** => located at [`scripts/env.zsh`](scripts/env.zsh)

> All scripts execute in a **subshell**, so your current terminal directory remains unchanged after they finish.

---

### ğŸ”‹ Installation

To install project dependencies run:

```bash
poetry install
```

This will automatically create a virtual environment and install all dependencies defined in `pyproject.toml`.

---

### ğŸ› ï¸ Build

To build the Python package, use:

```bash
poetry build
```

This command generates two distribution files inside the `dist/` folder:

- **Wheel (`.whl`)** â€” a prebuilt installable package
- **Source tarball (`.tar.gz`)** â€” a gzipped archive of your source code

---

### ğŸ“¦ Local Installation

To install the built wheel into your **local Poetry environment** (not globally or in the system environment):

```bash
poetry run pip install dist/java_pkg_cli-1.0.0-py3-none-any.whl
```

---

### ğŸš€ Running the CLIs

#### ğŸ” sync_env_cli

Run the Env Sync CLI to update all .env files(root, client, server), patch GitHub Actions workflows, and sync Kubernetes secrets:

```bash
poetry run python -m sync_env_cli env_mode
```

Example:

```bash
poetry run python -m sync_env_cli d
```

- **ğŸ’¡ Note**:
  For every patched file, a backup is created with a `.bkp` suffix.
  Example: `check_deploy.yml` => `check_deploy.yml.bkp`

##### ğŸ”§ Parameters

| Parameter    | Description                                                  | Example                                                    |
| ------------ | ------------------------------------------------------------ | ---------------------------------------------------------- |
| **env mode** | Required â€” determines which environment configuration to use | `d` => development<br>`p` => production<br>`t` => test<br> |

---

#### ğŸ§° java_pkg_cli

Run the Java package manager CLI using:

```bash
poetry run python -m java_pkg_cli group:artifact:version i
```

Example:

```bash
poetry run python -m java_pkg_cli example_group:example_artifact:1.2.3-cool_version_released i
```

##### ğŸ”§ Parameters

| Parameter       | Description                                                              | Example                                                                  |
| --------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------ |
| **library**     | Required â€” Gradle dependency in `group:artifact:optional-version` format | `io.projectreactor:reactor-core:3.6.6`                                   |
| **config type** | Optional â€” Gradle configuration type (`i` by default)                    | `i` => implementation<br>`tr` => testRuntimeOnly<br>...and more via `-h` |

Show all options:

```bash
poetry run python -m java_pkg_cli -h
```

---

#### ğŸ¨ svg_ng_cli

Run the SVG parser CLI using:

```bash
poetry run python -m svg_ng_cli path_to_svg_file output_folder_path [svg_type]
```

##### ğŸ”§ Parameters

| Parameter              | Description                                                 | Example                                                           |
| ---------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------- |
| **SVG file path**      | Required â€” path to the input `.svg` file                    | `assets/icons/user.svg`                                           |
| **Output folder path** | Required â€” folder where parsed components will be generated | `src/app/icons/`                                                  |
| **SVG type**           | Optional â€” determines how the SVG should be processed       | `f` => fill<br>`s` => stroke<br>`a` => advanced _(default: fill)_ |

---

### ğŸ§  Summary

| CLI              | Purpose                                 | Location                                             | Shortcut |
| ---------------- | --------------------------------------- | ---------------------------------------------------- | -------- |
| **java_pkg_cli** | Generate Gradle dependency snippets     | [apps/server/java_pkg_cli](apps/server/java_pkg_cli) | `ja`     |
| **svg_ng_cli**   | Convert SVGs into Angular components    | [apps/client/svg_ng_cli](apps/client/svg_ng_cli)     | `ngcv`   |
| **sync_env_cli** | Update .env files, Git and Kind secrets | [sync_env_cli](sync_env_cli)                         | `ue`     |

---

## ğŸª¾ Branches & Commits

When looking at the **Git history**, youâ€™ll notice a recurring pattern where each entry shows the **branch name** followed by an arrow **=>** and then the **commit message**.

For example:

```bash
ğŸª¾ recover_pwd_2FA_backup_code => ğŸ› ï¸ validated endpoint
```

This is the convention I follow to make it obvious which branch the work came from. That way, even after I **merge** and **delete** a branch, its commits still carry a **clear trace** of their **origin**.

For clarity, I also configure Git to always create a **merge commit** (**no fast-forward** merges).
This ensures that the history explicitly shows where a branch **forked off** and where it was **merged back in**.
This makes the development process easier to follow because you can see the **â€œpassagesâ€** of **each feature** or fix across the **project timeline**

---

### ğŸ“‘ Emoji Legend

- **âš ï¸ Critical** => local build works, but errors appear at **deploy** / **CI/CD**

- **ğŸ“œ Docs** => documentation updates

- **ğŸ› Bugfix** => fixes for reported issues or errors

- **ğŸ”¥ New** => new features

- **ğŸ¨ Refactor** => code cleanups / restructuring without changing behavior

- **ğŸ§ª Tests** => adding or improving test coverage

- **ğŸ› ï¸ Default** => normal workflow / maintenance

For example:

```bash
ğŸª¾ recover_pwd_2FA_backup_code => ğŸ› fix backup_code validation

ğŸª¾ sql_root_table => ğŸ¨ refactor method to_d to parse bytes as hex

ğŸª¾ main => ğŸ“œ updated project readme
```

I find that this style makes the **Git history** much easier to **scan quickly** and to **search** by **commit type**

---

## âœï¸ Final Notes

I hope you find the project interesting â€” if not, the app doesnâ€™t come with a refund policy ğŸ’°

Thanks for checking out the repo âœŒğŸ¼
